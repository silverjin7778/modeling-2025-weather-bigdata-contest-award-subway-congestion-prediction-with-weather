{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e470de65-a5fa-4ca8-8ead-c2a444b8a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\n",
    "    'data.parquet',\n",
    "    engine='pyarrow'         # 저장 시 사용한 엔진과 동일하게 지정\n",
    ")\n",
    "test_loaded = pd.read_parquet(\n",
    "    'test.parquet',\n",
    "    engine='pyarrow'         # 저장 시 사용한 엔진과 동일하게 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7f0edc-bd3b-4240-b78f-e970d98c284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature / target 정의\n",
    "ordered_cols = ['Direction', 'time_period']\n",
    "cat_cols     = [\n",
    "                'station_number'\n",
    "                , 'address'\n",
    "               # , 'station_name'\n",
    "               ] + ordered_cols\n",
    "num_cols = [\n",
    "    'HM','RN_DAY','RN_HR1',\n",
    "    #'SI',\n",
    "    'TA','WD','WS'\n",
    "    ,'STN'\n",
    "    ,'sin_dom','cos_dom','sin_dow','cos_dow','sin_hod','cos_hod'\n",
    "    ,'sin_wom','cos_wom','sin_woy','cos_woy','sin_doy','cos_doy'\n",
    "    ,'day','day_of_year','hour'\n",
    "    ,'is_day_before_holiday','is_day_after_holiday','is_holiday','is_weekend'\n",
    "    ,'month','transfer','week_of_month','week_of_year','weekday','year'\n",
    "    ,'신설역', '신규관측소'\n",
    "]\n",
    "feature_cols = num_cols + ordered_cols + cat_cols\n",
    "target_col   = 'Congestion'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311835f5-cb9c-4bc1-b31c-ce31b53613bc",
   "metadata": {},
   "source": [
    "# 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b1b1f6-82da-42b9-abc2-870fefebb24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred  = model.predict(X_val)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    r2   = r2_score(y_val, y_pred)\n",
    "    \n",
    "    return {'Model': name, 'Time(s)': elapsed, 'RMSE': rmse, 'R2': r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4033e0-5cae-42d7-9d92-d312d1f312a1",
   "metadata": {},
   "source": [
    "# 1~8호선 각각 LGBM, CB 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee91caf-1094-4e95-bb21-1b53d3869ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2612\n",
      "[LightGBM] [Info] Number of data points in the train set: 2251468, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 18.002817\n",
      "[Line 1] LGBM: RMSE=7.877, R2=0.852, Time=9.6s\n",
      "[Line 1] CAT: RMSE=5.479, R2=0.929, Time=255.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2542\n",
      "[LightGBM] [Info] Number of data points in the train set: 1596672, number of used features: 95\n",
      "[LightGBM] [Info] Start training from score 28.565433\n",
      "[Line 2] LGBM: RMSE=10.431, R2=0.762, Time=10.3s\n",
      "[Line 2] CAT: RMSE=11.665, R2=0.703, Time=177.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2553\n",
      "[LightGBM] [Info] Number of data points in the train set: 1598990, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score 19.906141\n",
      "[Line 3] LGBM: RMSE=5.820, R2=0.914, Time=10.0s\n",
      "[Line 3] CAT: RMSE=6.429, R2=0.895, Time=179.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2530\n",
      "[LightGBM] [Info] Number of data points in the train set: 1638761, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 21.225119\n",
      "[Line 4] LGBM: RMSE=7.913, R2=0.859, Time=8.4s\n",
      "[Line 4] CAT: RMSE=5.384, R2=0.935, Time=168.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2582\n",
      "[LightGBM] [Info] Number of data points in the train set: 1770249, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score 20.651826\n",
      "[Line 5] LGBM: RMSE=7.170, R2=0.864, Time=8.3s\n",
      "[Line 5] CAT: RMSE=4.995, R2=0.934, Time=183.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2485\n",
      "[LightGBM] [Info] Number of data points in the train set: 1451520, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 15.109336\n",
      "[Line 6] LGBM: RMSE=6.808, R2=0.813, Time=6.9s\n",
      "[Line 6] CAT: RMSE=7.710, R2=0.760, Time=140.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2532\n",
      "[LightGBM] [Info] Number of data points in the train set: 1978368, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 23.131690\n",
      "[Line 7] LGBM: RMSE=9.992, R2=0.809, Time=9.5s\n",
      "[Line 7] CAT: RMSE=6.825, R2=0.911, Time=202.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2413\n",
      "[LightGBM] [Info] Number of data points in the train set: 629160, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score 21.295373\n",
      "[Line 8] LGBM: RMSE=6.001, R2=0.935, Time=3.1s\n",
      "[Line 8] CAT: RMSE=4.620, R2=0.962, Time=59.2s\n",
      "\n",
      "=== 전체 라인·모델별 실행 시간·성능 비교 ===\n",
      "   Model     Time(s)       RMSE        R2  Line\n",
      "0   LGBM    9.604774   7.876524  0.852497     1\n",
      "1    CAT  255.308370   5.479455  0.928615     1\n",
      "2   LGBM   10.326076  10.431055  0.762498     2\n",
      "3    CAT  177.145799  11.665339  0.702966     2\n",
      "4   LGBM    9.955862   5.820142  0.913948     3\n",
      "5    CAT  179.791089   6.428667  0.895013     3\n",
      "6   LGBM    8.439031   7.912993  0.859456     4\n",
      "7    CAT  168.116032   5.384204  0.934931     4\n",
      "8   LGBM    8.282786   7.169554  0.863648     5\n",
      "9    CAT  183.700930   4.995188  0.933812     5\n",
      "10  LGBM    6.942290   6.808427  0.812974     6\n",
      "11   CAT  140.492593   7.710238  0.760148     6\n",
      "12  LGBM    9.452847   9.991821  0.809120     7\n",
      "13   CAT  202.591715   6.824788  0.910947     7\n",
      "14  LGBM    3.085980   6.000524  0.935274     8\n",
      "15   CAT   59.182165   4.619697  0.961636     8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 전처리·평가용\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics      import mean_squared_error, r2_score\n",
    "\n",
    "# ── 선형 계열 회귀 모델 ──\n",
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "# ── 트리 & 앙상블 ──\n",
    "from sklearn.ensemble      import (\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor\n",
    ")\n",
    "\n",
    "# ── 신경망 & 부스팅 ──\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost                 import XGBRegressor\n",
    "from lightgbm                import LGBMRegressor\n",
    "from catboost                import CatBoostRegressor\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 미리 정의해야 할 변수\n",
    "# df: 학습용 DataFrame (컬럼에 'Line', 'TM', STN, address, feature_cols, target_col 포함)\n",
    "# test: 테스트용 DataFrame (컬럼 구조 동일)\n",
    "# feature_cols: predictor로 사용할 컬럼 리스트\n",
    "# target_col: 예측 대상 컬럼 이름 (문자열)\n",
    "# cat_cols: 범주형으로 one-hot encoding 할 컬럼 리스트 (예: ['STN','address'])\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Time(s)': time.time() - t0,\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),\n",
    "        'R2': r2_score(y_val, y_pred)\n",
    "    }\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for line in range(1, 9):\n",
    "    # 1) subset & sort\n",
    "    df_line   = df [df['Line']==line].sort_values('TM').copy()\n",
    "    test_line = test_loaded[test_loaded['Line']==line].copy()\n",
    "\n",
    "    # 2) 카테고리 지정\n",
    "    for col in cat_cols:\n",
    "        df_line[col]   = df_line[col].astype('category')\n",
    "        test_line[col] = test_line[col].astype('category')\n",
    "\n",
    "    # 3) feature & target\n",
    "    X      = df_line[feature_cols]\n",
    "    y      = df_line[target_col].astype(int)\n",
    "    X_test = test_line[feature_cols]\n",
    "\n",
    "    # 4) 원-핫 인코딩\n",
    "    X_enc      = pd.get_dummies(X,      columns=cat_cols, drop_first=False)\n",
    "    X_test_enc = pd.get_dummies(X_test, columns=cat_cols, drop_first=False)\n",
    "\n",
    "    # 5) 중복 컬럼 제거 & 정렬, 누락 채움\n",
    "    X_enc      = X_enc.loc[:, ~X_enc.columns.duplicated()]\n",
    "    X_test_enc = X_test_enc.loc[:, ~X_test_enc.columns.duplicated()]\n",
    "    X_test_enc = X_test_enc.reindex(columns=X_enc.columns, fill_value=0)\n",
    "\n",
    "    # 6) 정규화\n",
    "    mm             = MinMaxScaler()\n",
    "    X_scaled       = mm.fit_transform(X_enc)\n",
    "    X_test_scaled  = mm.transform(X_test_enc)\n",
    "\n",
    "    # 7) 시간 순 분할 (train:val = 8:2)\n",
    "    split_idx = int(len(X_scaled) * 0.8)\n",
    "    X_train, X_val = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "    y_train, y_val = y.values[:split_idx],    y.values[split_idx:]\n",
    "\n",
    "    # 8) 모델별 평가\n",
    "    for name, model in [\n",
    "\n",
    "        ('LGBM', LGBMRegressor(n_jobs=-1, random_state=42)),\n",
    "        ('CAT',  CatBoostRegressor(verbose=0, random_state=42))\n",
    "    ]:\n",
    "        res = evaluate_model(name, model, X_train, y_train, X_val, y_val)\n",
    "        res['Line'] = line\n",
    "        all_results.append(res)\n",
    "        print(f\"[Line {line}] {name}: RMSE={res['RMSE']:.3f}, R2={res['R2']:.3f}, Time={res['Time(s)']:.1f}s\")\n",
    "\n",
    "# 9) 종합 결과 DataFrame 생성 및 저장\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(\"\\n=== 전체 라인·모델별 실행 시간·성능 비교 ===\")\n",
    "print(results_df)\n",
    "\n",
    "# CSV로 저장 (필요시)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "results_df.to_csv('results/model_performance_all_lines.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
