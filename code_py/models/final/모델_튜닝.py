# ---------------------------------------------------------------
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------------------------------------------

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams['font.family']='Malgun Gothic'

import pandas as pd
df = pd.read_parquet(
    'data.parquet',
    engine='pyarrow'         # ì €ì¥ ì‹œ ì‚¬ìš©í•œ ì—”ì§„ê³¼ ë™ì¼í•˜ê²Œ ì§€ì •
)
test_loaded = pd.read_parquet(
    'test.parquet',
    engine='pyarrow'         # ì €ì¥ ì‹œ ì‚¬ìš©í•œ ì—”ì§„ê³¼ ë™ì¼í•˜ê²Œ ì§€ì •
)

# feature / target ì •ì˜
ordered_cols = ['Direction', 'time_period']
cat_cols     = [
                'station_number'
                , 'address'
               ] + ordered_cols
num_cols = [
    'HM','RN_DAY','RN_HR1',
    'WD','WS'
    ,'STN'
    ,'sin_dom','cos_dom','sin_dow','cos_dow','sin_hod','cos_hod'
    ,'sin_wom','cos_wom','sin_woy','cos_woy','sin_doy','cos_doy'
    ,'day','day_of_year','hour'
    ,'is_day_before_holiday','is_day_after_holiday','is_holiday','is_weekend'
    ,'month','transfer','week_of_month','week_of_year','weekday','year'
    ,'ì‹ ì„¤ì—­', 'ì‹ ê·œê´€ì¸¡ì†Œ'
]
feature_cols = num_cols + ordered_cols + cat_cols
target_col   = 'Congestion'

results = []
final_results = []
print('ì™„ë£Œ')

df.shape

import matplotlib.pyplot as plt
import seaborn as sns

# 4í–‰Ã—2ì—´ FacetGrid
g = sns.FacetGrid(df, col='Line', col_wrap=2, height=3, sharex=False, sharey=False)
g.map(sns.histplot, 'Congestion', bins=30, kde=True)
g.set_titles('Line {col_name}')
g.set_axis_labels('í˜¼ì¡ë„ (%)','ë¹ˆë„')
plt.tight_layout()
plt.show()

# í˜¸ì„ ë³„ ë°•ìŠ¤í”Œë¡¯ì€ ê·¸ëŒ€ë¡œ
plt.figure(figsize=(8,4))
sns.boxplot(x='Line', y='Congestion', data=df)
plt.title('í˜¸ì„ ë³„ í˜¼ì¡ë„ ë°•ìŠ¤í”Œë¡¯')
plt.xlabel('í˜¸ì„ ')
plt.ylabel('í˜¼ì¡ë„ (%)')
plt.tight_layout()
plt.show()


# ---------------------------------------------------------------
# ëœë¤ì„œì¹˜ : 7í˜¸ì„ ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
# ---------------------------------------------------------------

from sklearn.model_selection import RandomizedSearchCV
from xgboost import XGBRegressor
from sklearn.preprocessing import MinMaxScaler
import pandas as pd
import numpy as np


# í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¶„í¬
param_dist = {
    'n_estimators': [500, 1000, 2000],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [8, 10, 12],
    'subsample': [0.5, 0.7, 0.9],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'reg_alpha': [0, 0.1, 0.3],
    'reg_lambda': [0.3, 0.5, 0.8],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 1, 3]
}

# 7í˜¸ì„ ë§Œ í•„í„°ë§
line = 7
df_line = df[df['Line'] == line].sort_values('TM')

# Feature / target ì¶”ì¶œ ë° ì¸ì½”ë”©
X = pd.get_dummies(df_line[feature_cols], columns=cat_cols, drop_first=False)
y = df_line[target_col].astype(int)

# ìŠ¤ì¼€ì¼ë§
scaler = MinMaxScaler().fit(X)
X_scaled = scaler.transform(X).astype(np.float32)

# XGB ëª¨ë¸ê³¼ RandomizedSearchCV ì„¸íŒ…
xgb = XGBRegressor(
    tree_method='hist',
    eval_metric='rmse',
    random_state=42,
    verbosity=0
)
rnd_search = RandomizedSearchCV(
    estimator=xgb,
    param_distributions=param_dist,
    n_iter=5,
    scoring='neg_root_mean_squared_error',
    cv=3,
    random_state=42,
    n_jobs=-1,
    verbose=1
)

# ì„œì¹˜ ì‹¤í–‰ & ê²°ê³¼ ì¶œë ¥
rnd_search.fit(X_scaled, y)
print(f"ğŸ† 7í˜¸ì„  ìµœì  íŒŒë¼ë¯¸í„°: {rnd_search.best_params_}")
